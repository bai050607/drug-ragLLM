from neo4j import GraphDatabase
from typing import Dict, List, Optional, Any, Set
import os
import json
from llama_index.core import Document, VectorStoreIndex
from qianwen_class import QianwenEmbedding, QianwenLLM
from prompt import recommend_prompt as PROMPT
from util import remove_think_blocks as chunk_text
from llama_index.vector_stores.neo4jvector import Neo4jVectorStore
from llama_index.core.storage.storage_context import StorageContext


class DrugGraph:
    def __init__(
        self,
        url: str = "bolt://localhost:7687",  # Neo4jæ•°æ®åº“çš„URL
        username: str = "neo4j",  # Neo4jæ•°æ®åº“çš„ç”¨æˆ·å
        password: str = "12345678",  # Neo4jæ•°æ®åº“çš„å¯†ç 
    ):
        self.driver = GraphDatabase.driver(
            url, auth=(username, password)
        )  # åˆ›å»ºNeo4jæ•°æ®åº“é©±åŠ¨
        self.url = url
        self.username = username
        self.password = password
        self._query_engine = None  # å»¶è¿Ÿåˆå§‹åŒ– 
        self._candidate_names: Optional[Set[str]] = None


    def _get_query_engine(self):
        """è·å–æˆ–åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆåŸºäºNeo4jæ··åˆæœç´¢ï¼Œå»¶è¿Ÿåˆå§‹åŒ–ï¼‰ã€‚"""
        if self._query_engine is None:
            print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–Neo4jæ··åˆæ£€ç´¢å¼•æ“...")
            llm = QianwenLLM()
            embed_model = QianwenEmbedding()
            neo4j_vector = Neo4jVectorStore(
                url=self.url, 
                username=self.username, 
                password=self.password, 
                embedding_dimension=1024,
                text_node_property="name",  # ä½¿ç”¨ name å±æ€§ä½œä¸ºæ–‡æœ¬
                embedding_node_property="embedding",  # ä½¿ç”¨ embedding å±æ€§
                node_label="Node",  # ä½ çš„èŠ‚ç‚¹æ ‡ç­¾
                hybrid_search=True  # å¯ç”¨Neo4jå†…ç½®æ··åˆæœç´¢
            )
            storage_context = StorageContext.from_defaults(vector_store=neo4j_vector)
            index = None
            try:
                print("ğŸ’¾ æ­£åœ¨ä» Neo4j æ··åˆå‘é‡å­˜å‚¨æ„å»ºç´¢å¼•ï¼ˆå…é‡å»ºï¼‰...")
                index = VectorStoreIndex.from_vector_store(
                    vector_store=neo4j_vector,
                    storage_context=storage_context,
                    embed_model=embed_model,
                )
                print("âœ… æˆåŠŸä» Neo4j æ··åˆå‘é‡å­˜å‚¨æ„å»ºç´¢å¼•")
            except Exception as e:
                print(f"âš ï¸ åŸºäºå‘é‡å­˜å‚¨æ„å»ºç´¢å¼•å¤±è´¥ï¼Œå°†å›é€€å…¨é‡æ„å»ºï¼š{e}")
            if index is None:
                print("ğŸ“Š ä» Neo4j åˆ†é¡µæ‹‰å–å…¨éƒ¨èŠ‚ç‚¹å¹¶æ„å»ºç´¢å¼•...")
                docs: List[Document] = []
                batch_size = 5000
                total = 0
                with self.driver.session() as session:
                    skip = 0
                    while True:
                        cypher = (
                            "MATCH (n) WHERE n.name IS NOT NULL "
                            "RETURN n SKIP $skip LIMIT $limit"
                        )
                        records = list(session.run(cypher, skip=skip, limit=batch_size))
                        if not records:
                            break
                        for rec in records:
                            node = rec["n"]
                            labels = list(node.labels)
                            properties = dict(node)
                            text_parts = []
                            text_parts.append(f"åç§°ï¼š{properties.get('name', 'æœªçŸ¥')}")
                            if 'Disease' in labels:
                                for key, value in properties.items():
                                    if key != 'name' and value is not None:
                                        if isinstance(value, str) and len(value.strip()) > 0:
                                            value_str = str(value).strip()
                                            if len(value_str) > 200:  # é™åˆ¶å•ä¸ªå±æ€§å€¼é•¿åº¦
                                                value_str = value_str[:200] + "..."
                                            text_parts.append(f"{key}ï¼š{value_str}")
                                        elif not isinstance(value, str):
                                            text_parts.append(f"{key}ï¼š{value}")
                            else:
                                if labels:
                                    text_parts.append(f"ç±»å‹ï¼š{', '.join(labels)}")
                            text = "ï¼›".join(text_parts)
                            metadata = {"name": properties.get('name'), "labels": labels}
                            if 'Disease' in labels:
                                metadata["entity_type"] = "Disease"
                                if "cure_lasttime" in properties:
                                    metadata["cure_lasttime"] = properties["cure_lasttime"]
                                if "cured_prob" in properties:
                                    metadata["cured_prob"] = properties["cured_prob"]
                            docs.append(Document(text=text, metadata=metadata))
                        total += len(records)
                        skip += batch_size
                        print(f"ğŸ“¥ å·²åŠ è½½ {total} æ¡èŠ‚ç‚¹ä¸ºæ–‡æ¡£...")

                if not docs:
                    raise RuntimeError("æœªä» Neo4j æ‹‰å–åˆ°ä»»ä½•èŠ‚ç‚¹ï¼Œæ— æ³•æ„å»ºå‘é‡ç´¢å¼•")

                print(f"ğŸ“š å…¨é‡èŠ‚ç‚¹æ–‡æ¡£æ•°ï¼š{len(docs)}ï¼Œå¼€å§‹æ„å»ºæ··åˆå‘é‡ç´¢å¼•...")
                index = VectorStoreIndex.from_documents(
                    docs,
                    storage_context=storage_context,
                    embed_model=embed_model,
                )
            self._query_engine = index.as_query_engine(llm=llm, similarity_top_k=10)
            print("âœ… Neo4jæ··åˆæ£€ç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        return self._query_engine

    def retrieve_medical_info(self, medical_text: str) -> str:
        """åŸºäºNeo4jæ··åˆæœç´¢æ£€ç´¢ç›¸å…³åŒ»ç–—ä¿¡æ¯"""
        try:
            # ä½¿ç”¨Neo4jå†…ç½®æ··åˆæœç´¢ï¼ˆå‘é‡+å…¨æ–‡+å›¾æœç´¢ï¼‰
            import re
            cleaned_text = re.sub(r'[^\u4e00-\u9fff\w\s.,;:!?()ï¼ˆï¼‰ã€ã€‘""''ã€ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]', '', str(medical_text))
            cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
            print("length:",len(cleaned_text))
            # ä½¿ç”¨Neo4jå†…ç½®æ··åˆæœç´¢ï¼ˆå‘é‡+å…¨æ–‡+å›¾æœç´¢ï¼‰
            query_engine = self._get_query_engine()
            retrieved_nodes = query_engine.retriever.retrieve(cleaned_text)
            
            # ç›´æ¥è¿”å›æ‰€æœ‰æ£€ç´¢åˆ°çš„èŠ‚ç‚¹
            result = []
            for node in retrieved_nodes:
                result.append(f"{node.text}")
            
            print("æ£€ç´¢ç»“æœ:", result)
            return "ã€".join(result) if result else "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
            
        except Exception as e:
            print(f"âŒ æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return f"æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"

    def query_medical_advice(self, medical_text: str, retrieved_info: Optional[str] = None) -> str:
        """åŸºäºç—…å†æ–‡æœ¬ç”ŸæˆåŒ»ç–—å»ºè®®"""
        try:
            query_engine = self._get_query_engine()
            # åŠ è½½ï¼ˆç¼“å­˜ï¼‰å€™é€‰è¯ç‰©é›†åˆ
            candidate_names = self._load_candidate_names()
            query = "è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯åšå‡ºè¯ç‰©æ¨èï¼Œè¿”å›å€¼ä»…ä¸ºç”±è¯ç‰©ç»„æˆçš„åˆ—è¡¨ã€‚\n"
            # æç®€æç¤ºè¯ï¼ˆå‡å°‘ tokenï¼‰ï¼šä»…çº¦æŸè¾“å‡ºä¸å¿…è¦ä¸Šä¸‹æ–‡
            query += "ç—…ä¾‹ä¿¡æ¯ï¼š{medical_text}\n"
            if retrieved_info:
                query += f"çŸ¥è¯†åº“æ£€ç´¢å¯èƒ½èŠ‚ç‚¹ï¼š{retrieved_info}\n"
            response = query_engine.query(query)
            text = str(response)
            text = chunk_text(text)
            print(text)
            # è§£ææ¨¡å‹è¾“å‡ºä¸ºåˆ—è¡¨
            drugs: List[str] = []
            try:
                parsed = json.loads(text)
                if isinstance(parsed, list):
                    drugs = [str(x).strip() for x in parsed if isinstance(x, (str, int, float))]
            except Exception:
                drugs = []
            # è¿‡æ»¤è‡³å€™é€‰é›†åˆï¼ˆè‹¥å€™é€‰é›†åˆå¯ç”¨ï¼‰
            if candidate_names:
                filtered: List[str] = []
                seen: Set[str] = set()
                for name in drugs:
                    if name in candidate_names and name not in seen:
                        filtered.append(name)
                        seen.add(name)
                return json.dumps(filtered, ensure_ascii=False)
            else:
                # è‹¥æ²¡æœ‰å€™é€‰é›†åˆå¯ç”¨ï¼Œç›´æ¥å›ä¼ åŸå§‹ JSONï¼ˆæˆ–ç©ºæ•°ç»„ï¼‰
                return json.dumps(drugs, ensure_ascii=False)
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return f"æŠ±æ­‰ï¼ŒæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"

    def _load_candidate_names(self, force_reload: bool = False) -> Set[str]:
        """åŠ è½½å¹¶ç¼“å­˜å€™é€‰è¯ç‰©é›†åˆã€‚"""
        if self._candidate_names is not None and not force_reload:
            return self._candidate_names
        candidates_path = os.getenv(
            "CANDIDATE_DRUGS_JSON",
            os.path.join(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")), "data", "å€™é€‰è¯ç‰©åˆ—è¡¨.json"),
        )
        names: Set[str] = set()
        if os.path.isfile(candidates_path):
            try:
                with open(candidates_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        names = {str(x).strip() for x in data if str(x).strip()}
            except Exception:
                names = set()
        self._candidate_names = names
        return names


    def prime_model_with_rules(self, include_full_list: bool = False, max_names: int = 200) -> None:
        """åœ¨æ‰¹é‡å¼€å§‹å‰ï¼Œå…ˆå‘é€ä¸€æ¬¡æç¤ºè¯ï¼Œå‘ŠçŸ¥è§„åˆ™ä¸å€™é€‰é›†åˆã€‚

        include_full_list: æ˜¯å¦åœ¨æç¤ºä¸­åŒ…å«å®Œæ•´å€™é€‰æ¸…å•ï¼ˆå¯èƒ½è¾ƒé•¿ï¼‰ã€‚
        max_names: è‹¥ä¸åŒ…å«å…¨é‡ï¼Œåˆ™ç¤ºä¾‹å‰ N é¡¹ï¼Œæ§åˆ¶ tokenã€‚
        """
        print("ğŸ”„ æ­£åœ¨é¢„çƒ­æ¨¡å‹...")
        query_engine = self._get_query_engine()
        names = list(self._load_candidate_names())
        names.sort()
        if include_full_list:
            listing = "ã€".join(names)
        else:
            listing = "ã€".join(names[:max_names])
        prompt=PROMPT.replace("{list}", listing)
        # try:
        llm = QianwenLLM(
            api_key="dummy_key",
            api_base="http://localhost:11434/v1",
            model="qwq:latest"
        )
        resp = llm.complete(prompt)
        tt = str(resp)
        tt = chunk_text(tt)
        print(tt)
        print("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
        # except Exception as e:
        #     print(f"âš ï¸ æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")

    # def add_embedding_for_graph(self):
    #     """åˆ†å±‚åµŒå…¥ç­–ç•¥ï¼šä¸ºä¸åŒå®ä½“ç±»å‹ç”Ÿæˆä¸åŒè´¨é‡çš„åµŒå…¥å‘é‡ï¼ˆå†™å›èŠ‚ç‚¹å±æ€§ï¼‰ã€‚"""
    #     qianwen_api_base = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    #     qianwen_api_key = os.getenv("DASHSCOPE_API_KEY")
    #     embedder = QianwenEmbedding(api_key=qianwen_api_key, api_base=qianwen_api_base, embed_dim=1024)

    #     # 1) Diseaseï¼šç”¨å®Œæ•´æè¿°ç”Ÿæˆè¾ƒä¸°å¯Œçš„å‘é‡å¹¶å†™å› full_description
    #     disease_query = (
    #         """
    #     MATCH (n:Disease)
    #     WHERE n.desc IS NOT NULL AND n.desc <> '' AND n.embedding IS NULL
    #     RETURN n
    #         """
    #     )
    #     updated = 0
    #     skipped = 0
    #     with self.driver.session() as session:
    #         disease_records = session.run(disease_query).data()
    #         total = len(disease_records)
    #         print(f"[EMB] Disease éœ€è¦å¤„ç†: {total} ä¸ªï¼ˆè·³è¿‡å·²æœ‰åµŒå…¥çš„èŠ‚ç‚¹ï¼‰")
    #         for idx, record in enumerate(disease_records, start=1):
    #             try:
    #                 node = record["n"]
    #                 node_name = node.get("name", "")
                    
    #                 # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²æœ‰åµŒå…¥ï¼ˆåŒé‡ä¿é™©ï¼‰
    #                 if node.get("embedding") is not None:
    #                     skipped += 1
    #                     print(f"[EMB] Disease è·³è¿‡å·²æœ‰åµŒå…¥: {node_name}")
    #                     continue
                    
    #                 description_parts: List[str] = []
    #                 if "desc" in node:
    #                     description_parts.append(f"ç–¾ç—…æè¿°ï¼š{node['desc']}")
    #                 if "cause" in node:
    #                     description_parts.append(f"ç—…å› ï¼š{node['cause']}")
    #                 if "prevent" in node:
    #                     description_parts.append(f"é¢„é˜²ï¼š{node['prevent']}")
    #                 if "cure_lasttime" in node:
    #                     description_parts.append(f"æ²»æ„ˆæ—¶é—´ï¼š{node['cure_lasttime']}")
    #                 if "cured_prob" in node:
    #                     description_parts.append(f"æ²»æ„ˆæ¦‚ç‡ï¼š{node['cured_prob']}")
    #                 if "easy_get" in node:
    #                     description_parts.append(f"æ˜“æ„Ÿäººç¾¤ï¼š{node['easy_get']}")
    #                 full_description = "ï¼›".join(description_parts) if description_parts else node_name

    #                 vector = embedder.get_text_embedding(full_description)
    #                 update_query = (
    #                     """
    #                 MATCH (n:Disease {name: $name})
    #                 SET n.embedding = $embedding,
    #                     n.full_description = $full_description
    #                     """
    #                 )
    #                 session.run(update_query, name=node_name, embedding=vector, full_description=full_description)
    #                 updated += 1
    #                 print(f"[EMB] Disease è¿›åº¦: {idx}/{total}")
    #             except Exception as e:
    #                 print(f"å¤„ç† Disease å®ä½“æ—¶å‡ºé”™: {e}")
    #                 continue
    #     print(f"[EMB] Disease å‘é‡å†™å›å®Œæˆï¼Œå…± {updated} ä¸ªï¼Œè·³è¿‡ {skipped} ä¸ª")

    #     # 2) å…¶ä»–å®ä½“ï¼šç”¨è¾ƒç®€å•çš„æ–‡æœ¬
    #     remaining_entities = ["Drug", "Symptom", "Food", "Check", "Cure", "Producer", "Department"]
    #     for entity_type in remaining_entities:
    #         with self.driver.session() as session:
    #             records = session.run(f"MATCH (n:{entity_type}) WHERE n.embedding IS NULL RETURN n").data()
    #             total = len(records)
    #             print(f"[EMB] {entity_type} éœ€è¦å¤„ç†: {total} ä¸ªï¼ˆè·³è¿‡å·²æœ‰åµŒå…¥çš„èŠ‚ç‚¹ï¼‰")
    #             updated = 0
    #             skipped = 0
    #             for idx, record in enumerate(records, start=1):
    #                 try:
    #                     node = record["n"]
    #                     node_name = node.get("name", "")
                        
    #                     # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²æœ‰åµŒå…¥ï¼ˆåŒé‡ä¿é™©ï¼‰
    #                     if node.get("embedding") is not None:
    #                         skipped += 1
    #                         print(f"[EMB] {entity_type} è·³è¿‡å·²æœ‰åµŒå…¥: {node_name}")
    #                         continue
                        
    #                     simple_description = f"{entity_type}ï¼š{node_name}"
    #                     vector = embedder.get_text_embedding(simple_description)
    #                     update_query = (
    #                         f"MATCH (n:{entity_type}) WHERE n.name = $name "
    #                         "SET n.embedding = $embedding, n.simple_description = $simple_description"
    #                     )
    #                     session.run(update_query, name=node_name, embedding=vector, simple_description=simple_description)
    #                     updated += 1
    #                     print(f"[EMB] {entity_type} è¿›åº¦: {idx}/{total}")
    #                 except Exception as e:
    #                     print(f"å¤„ç† {entity_type} å®ä½“æ—¶å‡ºé”™: {e}")
    #                     continue
    #         print(f"[EMB] {entity_type} å‘é‡å†™å›å®Œæˆï¼Œå…± {updated} ä¸ªï¼Œè·³è¿‡ {skipped} ä¸ª")
        
