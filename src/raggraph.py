from neo4j import GraphDatabase
from typing import Dict, List, Optional, Any, Set
import os
import json
from llama_index.core import Document, VectorStoreIndex
from qianwen_class import QianwenEmbedding, QianwenLLM


class DrugGraph:
    def __init__(
        self,
        url: str = "bolt://localhost:7687",  # Neo4jæ•°æ®åº“çš„URL
        username: str = "neo4j",  # Neo4jæ•°æ®åº“çš„ç”¨æˆ·å
        password: str = "12345678",  # Neo4jæ•°æ®åº“çš„å¯†ç 
    ):
        self.driver = GraphDatabase.driver(
            url, auth=(username, password)
        )  # åˆ›å»ºNeo4jæ•°æ®åº“é©±åŠ¨
        self.url = url
        self.username = username
        self.password = password
        self._query_engine = None  # å»¶è¿Ÿåˆå§‹åŒ– 
        self._candidate_names: Optional[Set[str]] = None


    def _get_query_engine(self):
        """è·å–æˆ–åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆåŸºäºå‘é‡ç´¢å¼•ï¼Œå»¶è¿Ÿåˆå§‹åŒ–ï¼‰ã€‚"""
        if self._query_engine is None:
            print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–å‘é‡æ£€ç´¢å¼•æ“...")
            qianwen_api_base = "https://dashscope.aliyuncs.com/compatible-mode/v1"
            qianwen_api_key = os.getenv("DASHSCOPE_API_KEY")
            llm = QianwenLLM(
                api_key=qianwen_api_key,
                api_base=qianwen_api_base,
                model="qwen-turbo",
                temperature=0.0,
            )
            embed_model = QianwenEmbedding(
                api_key=qianwen_api_key,
                api_base=qianwen_api_base,
                embed_dim=256,
            )

            # ä» Neo4j æ‹‰å–èŠ‚ç‚¹ï¼Œæ„é€ æ–‡æ¡£
            print("ğŸ“Š æ­£åœ¨ä» Neo4j æ‹‰å–èŠ‚ç‚¹...")
            docs: List[Document] = []
            with self.driver.session() as session:
                # å¯æ ¹æ®éœ€è¦è°ƒæ•´ LIMIT æˆ–æ‹¼æ¥æ›´å¤šå±æ€§
                cypher = (
                    "MATCH (n) WHERE n.name IS NOT NULL "
                    "RETURN labels(n) AS labels, n.name AS name LIMIT 1000"
                )
                for rec in session.run(cypher):
                    labels = rec["labels"] or []
                    name = rec["name"]
                    text = f"åç§°ï¼š{name}ï¼›æ ‡ç­¾ï¼š{', '.join(labels)}"
                    docs.append(Document(text=text, metadata={"name": name, "labels": labels}))
            
            print(f"ğŸ“š å·²æ‹‰å– {len(docs)} ä¸ªèŠ‚ç‚¹ï¼Œæ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•...")

            if not docs:
                raise RuntimeError("æœªä» Neo4j æ‹‰å–åˆ°ä»»ä½•èŠ‚ç‚¹ï¼Œæ— æ³•æ„å»ºå‘é‡ç´¢å¼•")

            index = VectorStoreIndex.from_documents(docs, embed_model=embed_model)
            self._query_engine = index.as_query_engine(llm=llm)
            print("âœ… å‘é‡æ£€ç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        return self._query_engine

    def retrieve_medical_info(self, medical_text: str) -> str:
        """åŸºäºç—…å†æ–‡æœ¬æ£€ç´¢ç›¸å…³åŒ»ç–—ä¿¡æ¯"""
        try:
            query_engine = self._get_query_engine()
            query = f"{medical_text}"
            print(query)
            response = query_engine.query(query)
            return str(response)
        except Exception as e:
            print(f"âŒ æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return f"æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"

    def query_medical_advice(self, medical_text: str, retrieved_info: Optional[str] = None) -> str:
        """åŸºäºç—…å†æ–‡æœ¬ç”ŸæˆåŒ»ç–—å»ºè®®"""
        try:
            query_engine = self._get_query_engine()
            # åŠ è½½ï¼ˆç¼“å­˜ï¼‰å€™é€‰è¯ç‰©é›†åˆ
            candidate_names = self._load_candidate_names()

            # æç®€æç¤ºè¯ï¼ˆå‡å°‘ tokenï¼‰ï¼šä»…çº¦æŸè¾“å‡ºä¸å¿…è¦ä¸Šä¸‹æ–‡
            query = "ä»…è¾“å‡ºå€™é€‰è¯ç‰©å†…çš„ä¸­æ–‡é€šç”¨åJSONæ•°ç»„ã€‚æ— åˆ™è¿”å›[]ã€‚\n"
            query += f"ç—…å†ï¼š{medical_text}\n"
            if retrieved_info:
                query += f"æ£€ç´¢ï¼š{retrieved_info}\n"
            response = query_engine.query(query)
            text = str(response)

            # è§£ææ¨¡å‹è¾“å‡ºä¸ºåˆ—è¡¨
            drugs: List[str] = []
            try:
                parsed = json.loads(text)
                if isinstance(parsed, list):
                    drugs = [str(x).strip() for x in parsed if isinstance(x, (str, int, float))]
            except Exception:
                drugs = []

            # è¿‡æ»¤è‡³å€™é€‰é›†åˆï¼ˆè‹¥å€™é€‰é›†åˆå¯ç”¨ï¼‰
            if candidate_names:
                filtered: List[str] = []
                seen: Set[str] = set()
                for name in drugs:
                    if name in candidate_names and name not in seen:
                        filtered.append(name)
                        seen.add(name)
                return json.dumps(filtered, ensure_ascii=False)
            else:
                # è‹¥æ²¡æœ‰å€™é€‰é›†åˆå¯ç”¨ï¼Œç›´æ¥å›ä¼ åŸå§‹ JSONï¼ˆæˆ–ç©ºæ•°ç»„ï¼‰
                return json.dumps(drugs, ensure_ascii=False)
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return f"æŠ±æ­‰ï¼ŒæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"

    def _load_candidate_names(self, force_reload: bool = False) -> Set[str]:
        """åŠ è½½å¹¶ç¼“å­˜å€™é€‰è¯ç‰©é›†åˆã€‚"""
        if self._candidate_names is not None and not force_reload:
            return self._candidate_names
        candidates_path = os.getenv(
            "CANDIDATE_DRUGS_JSON",
            os.path.join(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")), "data", "å€™é€‰è¯ç‰©åˆ—è¡¨.json"),
        )
        names: Set[str] = set()
        if os.path.isfile(candidates_path):
            try:
                with open(candidates_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        names = {str(x).strip() for x in data if str(x).strip()}
            except Exception:
                names = set()
        self._candidate_names = names
        return names


    def prime_model_with_rules(self, include_full_list: bool = False, max_names: int = 200) -> None:
        """åœ¨æ‰¹é‡å¼€å§‹å‰ï¼Œå…ˆå‘é€ä¸€æ¬¡æç¤ºè¯ï¼Œå‘ŠçŸ¥è§„åˆ™ä¸å€™é€‰é›†åˆã€‚

        include_full_list: æ˜¯å¦åœ¨æç¤ºä¸­åŒ…å«å®Œæ•´å€™é€‰æ¸…å•ï¼ˆå¯èƒ½è¾ƒé•¿ï¼‰ã€‚
        max_names: è‹¥ä¸åŒ…å«å…¨é‡ï¼Œåˆ™ç¤ºä¾‹å‰ N é¡¹ï¼Œæ§åˆ¶ tokenã€‚
        """
        print("ğŸ”„ æ­£åœ¨é¢„çƒ­æ¨¡å‹...")
        query_engine = self._get_query_engine()
        names = list(self._load_candidate_names())
        names.sort()
        if include_full_list:
            listing = "ã€".join(names)
        else:
            listing = "ã€".join(names[:max_names])
        prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—ç”¨è¯æ¨èç³»ç»Ÿã€‚æ¥ä¸‹æ¥çš„æ¯ä¸ªé—®é¢˜æˆ‘éƒ½ä¼šç»™ä½ ä¸€æ®µç—…å†æè¿°å’Œæ£€ç´¢å‡ºçš„ç›¸å…³åŒ»ç–—ä¿¡æ¯ï¼Œ"
            "ä½ éœ€è¦æ ¹æ®è¿™äº›å†…å®¹ï¼Œä»ä»¥ä¸‹å€™é€‰è¯ç‰©é›†åˆä¸­ä»”ç»†é€‰æ‹©éœ€è¦ä½¿ç”¨çš„è¯ç‰©ã€‚\n\n"
            "é‡è¦è¦æ±‚ï¼š\n"
            "1. åªèƒ½ä»å€™é€‰è¯ç‰©é›†åˆä¸­é€‰æ‹©ï¼Œä¸èƒ½æ¨èé›†åˆå¤–çš„ä»»ä½•è¯ç‰©\n"
            "2. å¿…é¡»ä»”ç»†åˆ†æç—…å†ä¸­çš„ç—‡çŠ¶ã€ç–¾ç—…ã€æ£€æŸ¥ç»“æœç­‰ä¿¡æ¯\n"
            "3. å¿…é¡»ç»“åˆæ£€ç´¢å‡ºçš„ç›¸å…³åŒ»ç–—ä¿¡æ¯è¿›è¡Œç»¼åˆåˆ¤æ–­\n"
            "4. åªè¿”å›è¯ç‰©åç§°çš„åˆ—è¡¨ï¼Œæ ¼å¼ä¸ºJSONæ•°ç»„ï¼Œå¦‚ï¼š[\"è¯ç‰©1\", \"è¯ç‰©2\"]\n"
            "5. å¦‚æœæ ¹æ®ç—…å†å’Œæ£€ç´¢ä¿¡æ¯æ— æ³•ç¡®å®šéœ€è¦ä»»ä½•è¯ç‰©ï¼Œåˆ™è¿”å›ç©ºæ•°ç»„ï¼š[]\n"
            "6. ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€å‰‚é‡ã€ç”¨æ³•ã€é€‚åº”ç—‡ç­‰é¢å¤–ä¿¡æ¯\n"
            "7. ä¸è¦è¾“å‡ºä»»ä½•éè¯ç‰©åç§°çš„å†…å®¹\n"
            "8. è¯ç‰©åç§°å¿…é¡»ä¸å€™é€‰é›†åˆä¸­çš„åç§°å®Œå…¨ä¸€è‡´\n\n"
            f"å€™é€‰è¯ç‰©é›†åˆï¼ˆå…±{len(names)}ç§è¯ç‰©ï¼‰ï¼š{listing}\n\n"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè¦æ±‚æ‰§è¡Œï¼Œç¡®ä¿è¾“å‡ºçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚"
        )
        try:
            _ = query_engine.query(prompt)
            print("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")

    # def add_embedding_for_graph(self):
    #     """åˆ†å±‚åµŒå…¥ç­–ç•¥ï¼šä¸ºä¸åŒå®ä½“ç±»å‹ç”Ÿæˆä¸åŒè´¨é‡çš„åµŒå…¥å‘é‡ï¼ˆå†™å›èŠ‚ç‚¹å±æ€§ï¼‰ã€‚"""
    #     qianwen_api_base = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    #     qianwen_api_key = os.getenv("DASHSCOPE_API_KEY")
    #     embedder = QianwenEmbedding(api_key=qianwen_api_key, api_base=qianwen_api_base, embed_dim=1024)

    #     # 1) Diseaseï¼šç”¨å®Œæ•´æè¿°ç”Ÿæˆè¾ƒä¸°å¯Œçš„å‘é‡å¹¶å†™å› full_description
    #     disease_query = (
    #         """
    #     MATCH (n:Disease)
    #     WHERE n.desc IS NOT NULL AND n.desc <> '' AND n.embedding IS NULL
    #     RETURN n
    #         """
    #     )
    #     updated = 0
    #     skipped = 0
    #     with self.driver.session() as session:
    #         disease_records = session.run(disease_query).data()
    #         total = len(disease_records)
    #         print(f"[EMB] Disease éœ€è¦å¤„ç†: {total} ä¸ªï¼ˆè·³è¿‡å·²æœ‰åµŒå…¥çš„èŠ‚ç‚¹ï¼‰")
    #         for idx, record in enumerate(disease_records, start=1):
    #             try:
    #                 node = record["n"]
    #                 node_name = node.get("name", "")
                    
    #                 # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²æœ‰åµŒå…¥ï¼ˆåŒé‡ä¿é™©ï¼‰
    #                 if node.get("embedding") is not None:
    #                     skipped += 1
    #                     print(f"[EMB] Disease è·³è¿‡å·²æœ‰åµŒå…¥: {node_name}")
    #                     continue
                    
    #                 description_parts: List[str] = []
    #                 if "desc" in node:
    #                     description_parts.append(f"ç–¾ç—…æè¿°ï¼š{node['desc']}")
    #                 if "cause" in node:
    #                     description_parts.append(f"ç—…å› ï¼š{node['cause']}")
    #                 if "prevent" in node:
    #                     description_parts.append(f"é¢„é˜²ï¼š{node['prevent']}")
    #                 if "cure_lasttime" in node:
    #                     description_parts.append(f"æ²»æ„ˆæ—¶é—´ï¼š{node['cure_lasttime']}")
    #                 if "cured_prob" in node:
    #                     description_parts.append(f"æ²»æ„ˆæ¦‚ç‡ï¼š{node['cured_prob']}")
    #                 if "easy_get" in node:
    #                     description_parts.append(f"æ˜“æ„Ÿäººç¾¤ï¼š{node['easy_get']}")
    #                 full_description = "ï¼›".join(description_parts) if description_parts else node_name

    #                 vector = embedder.get_text_embedding(full_description)
    #                 update_query = (
    #                     """
    #                 MATCH (n:Disease {name: $name})
    #                 SET n.embedding = $embedding,
    #                     n.full_description = $full_description
    #                     """
    #                 )
    #                 session.run(update_query, name=node_name, embedding=vector, full_description=full_description)
    #                 updated += 1
    #                 print(f"[EMB] Disease è¿›åº¦: {idx}/{total}")
    #             except Exception as e:
    #                 print(f"å¤„ç† Disease å®ä½“æ—¶å‡ºé”™: {e}")
    #                 continue
    #     print(f"[EMB] Disease å‘é‡å†™å›å®Œæˆï¼Œå…± {updated} ä¸ªï¼Œè·³è¿‡ {skipped} ä¸ª")

    #     # 2) å…¶ä»–å®ä½“ï¼šç”¨è¾ƒç®€å•çš„æ–‡æœ¬
    #     remaining_entities = ["Drug", "Symptom", "Food", "Check", "Cure", "Producer", "Department"]
    #     for entity_type in remaining_entities:
    #         with self.driver.session() as session:
    #             records = session.run(f"MATCH (n:{entity_type}) WHERE n.embedding IS NULL RETURN n").data()
    #             total = len(records)
    #             print(f"[EMB] {entity_type} éœ€è¦å¤„ç†: {total} ä¸ªï¼ˆè·³è¿‡å·²æœ‰åµŒå…¥çš„èŠ‚ç‚¹ï¼‰")
    #             updated = 0
    #             skipped = 0
    #             for idx, record in enumerate(records, start=1):
    #                 try:
    #                     node = record["n"]
    #                     node_name = node.get("name", "")
                        
    #                     # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²æœ‰åµŒå…¥ï¼ˆåŒé‡ä¿é™©ï¼‰
    #                     if node.get("embedding") is not None:
    #                         skipped += 1
    #                         print(f"[EMB] {entity_type} è·³è¿‡å·²æœ‰åµŒå…¥: {node_name}")
    #                         continue
                        
    #                     simple_description = f"{entity_type}ï¼š{node_name}"
    #                     vector = embedder.get_text_embedding(simple_description)
    #                     update_query = (
    #                         f"MATCH (n:{entity_type}) WHERE n.name = $name "
    #                         "SET n.embedding = $embedding, n.simple_description = $simple_description"
    #                     )
    #                     session.run(update_query, name=node_name, embedding=vector, simple_description=simple_description)
    #                     updated += 1
    #                     print(f"[EMB] {entity_type} è¿›åº¦: {idx}/{total}")
    #                 except Exception as e:
    #                     print(f"å¤„ç† {entity_type} å®ä½“æ—¶å‡ºé”™: {e}")
    #                     continue
    #         print(f"[EMB] {entity_type} å‘é‡å†™å›å®Œæˆï¼Œå…± {updated} ä¸ªï¼Œè·³è¿‡ {skipped} ä¸ª")
        
